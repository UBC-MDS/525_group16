{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "difficult-newman",
   "metadata": {},
   "source": [
    "# Milestone 1\n",
    "## DSCI 525 Web and Cloud Computing\n",
    "## Group 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-landing",
   "metadata": {},
   "source": [
    "This notebook downloads various observed and simulated rainfall data sets from New South Wales, Australia over the period of 1889 - 2014.  The data are then combined and basic exporatory data analyses are conducted using both Python and R programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "southern-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import rpy2.rinterface\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from memory_profiler import memory_usage\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.feather as feather\n",
    "# import rpy2.rinterface\n",
    "# import rpy2_arrow.pyarrow_rarrow as pyra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "varied-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext rpy2.ipython\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "biblical-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%R\n",
    "# library(dplyr)\n",
    "# library(arrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-guatemala",
   "metadata": {},
   "source": [
    "# Data Download\n",
    "The following code chunk downloads the data used in the subsequent analyses.  The data are downloaded from 'figshare.com'.  The file 'data.zip' is saved to a local directory called 'data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "announced-direction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 101.90 MiB, increment: 3.66 MiB\n",
      "Wall time: 20min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "# Print out time and memory taken for downloading data\n",
    "\n",
    "# This code is adapted from DSCI 525 lecture demonstration notebook (Gittu George, 2021,\n",
    "# https://github.ubc.ca/MDS-2020-21/DSCI_525_web-cloud-comp_students/blob/master/Lectures/Lecture_1_2.ipynb)\n",
    "url = f\"https://api.figshare.com/v2/articles/14096681\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"../data/\"\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)\n",
    "files = data[\"files\"]\n",
    "\n",
    "for file in files:\n",
    "    if file[\"name\"] in \"data.zip\":\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-soccer",
   "metadata": {},
   "source": [
    "After it has been downloaded locally, 'data.zip' is extracted and stored in the 'data' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "south-acoustic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 107.45 MiB, increment: 5.59 MiB\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "# Print out time and memory taken to extract data\n",
    "\n",
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), \"r\") as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-upgrade",
   "metadata": {},
   "source": [
    "So annoying to load all csvs into ram, combine, then resave.  Would be much easier if we could stitch the files together directly without loading them into RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-alfred",
   "metadata": {},
   "source": [
    "# Combining Data\n",
    "The following code chunk combines all of the unzipped rainfall data .csv files into a single file called 'combined_data.csv'.  This process is accomplished by creating a pandas dataframe called `full_df`, then one by one loading each .csv file and concatenating it with `full_df`.  This requires that all of the .csv files be read into a pandas dataframe variable and held in RAM at once.  In this case, this requires that almost 7 GB of data be held in RAM and manipulated.  Some computers will not be able to perform this data combining operation because they do not have sufficient RAM.  Even for systems which have sufficient RAM, performing simple operations (such as concatenation) on on a variable of this size are time consuming.  To demonstrate this, below the code chunk, we have included screen shots of the time and memory usage for the execution of this data combining operation.  To summarize, the time taken to complete this operation on each system are listed below (along with some general hardware specifications):\n",
    "1. Wall time: 7min 9s; Peak memory: 6891.53 MiB\n",
    "    - Processor: i7-10510U (4 cores, up to 4.90 GHz)\n",
    "    - RAM: 16 GB\n",
    "2. Wall time: 9min 46s; Peak memory: 3097.45 MiB\n",
    "    - Processor: i5\n",
    "    - RAM: 8 GB\n",
    "3. Wall time: 6min 5s; Peak memory: 7265.16 MiB\n",
    "    - Processor: i7-8700K (6 cores, up to 3.70 GHz)\n",
    "    - RAM: 16 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "standard-handle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 7230.48 MiB, increment: 7127.28 MiB\n",
      "Wall time: 6min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "# Print out time and memory taken to merge and save csv files\n",
    "\n",
    "file_names = os.listdir(output_directory)\n",
    "file_names = [file for file in file_names if file[-4:] == \".csv\"]\n",
    "\n",
    "\n",
    "cols = [\"lat_min\", \"lat_max\", \"lon_min\", \"lon_max\", \"rain (mm/day)\"]\n",
    "full_df = pd.DataFrame(columns=[\"model\"] + cols)\n",
    "full_df.index.rename(\"time\", inplace=True)\n",
    "\n",
    "for file in file_names:\n",
    "        model_name = re.search(\"^.*(?=_daily)\", file).group(0)\n",
    "    full_df = pd.concat(\n",
    "        [\n",
    "            full_df,\n",
    "            pd.read_csv(output_directory + file, index_col=0).assign(model=model_name),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "full_df.to_csv(output_directory + \"combined_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-percentage",
   "metadata": {},
   "source": [
    "1. Processor: i7-10510U (4 cores, up to 4.90 GHz); RAM: 16 GB\n",
    "\n",
    "![](../img/i7-10510_16GB-SP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-cancellation",
   "metadata": {},
   "source": [
    "2. Processor: 2.3 GHz Quad-Core Intel Core i5; RAM: 8GB\n",
    "\n",
    "![](../img/i5_8GB.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-blast",
   "metadata": {},
   "source": [
    "3. Processor: i7-8700K (6 cores, up to 3.70 GHz); RAM: 16 GB\n",
    "\n",
    "![](../img/i7-8700K_16GB_CZ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-chapel",
   "metadata": {},
   "source": [
    "## Task 5. Load the combined CSV to memory and perform a simple EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-instruction",
   "metadata": {},
   "source": [
    "### 1. Investigate at least 2 approaches and perform a simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mighty-ending",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3c7297abd118>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfull_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'full_df' is not defined"
     ]
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "former-blowing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 62513863 entries, 1889-01-01 12:00:00 to 2014-12-31 12:00:00\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   model          object \n",
      " 1   lat_min        float64\n",
      " 2   lat_max        float64\n",
      " 3   lon_min        float64\n",
      " 4   lon_max        float64\n",
      " 5   rain (mm/day)  float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 3.3+ GB\n"
     ]
    }
   ],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "exposed-parent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model             object\n",
       "lat_min          float64\n",
       "lat_max          float64\n",
       "lon_min          float64\n",
       "lon_max          float64\n",
       "rain (mm/day)    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-disney",
   "metadata": {},
   "source": [
    "#### Method 1: Loading in Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "every-stack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "AWI-ESM-1-1-LR       966420\n",
      "BCC-CSM2-MR         3035340\n",
      "BCC-ESM1             551880\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "CanESM5              551880\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "FGOALS-f3-L         3219300\n",
      "FGOALS-g3           1287720\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "MIROC6              2070900\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-HR       5154240\n",
      "MPI-ESM1-2-LR        966420\n",
      "MRI-ESM2-0          3037320\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "TaiESM1             3541230\n",
      "observed              46020\n",
      "dtype: int32\n",
      "peak memory: 5698.80 MiB, increment: 2152.75 MiB\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "import dask.dataframe as dd\n",
    "\n",
    "### Code adapted from DSCI 525 Lecture ipynb notebook (Gittu George, 2021)\n",
    "counts = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"../data/combined_data.csv\", chunksize=10_000_000):\n",
    "    counts = counts.add(chunk[\"model\"].value_counts(), fill_value=0)\n",
    "print(counts.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-little",
   "metadata": {},
   "source": [
    "#### Method 2: Using Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "disturbed-objective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "TaiESM1             3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "MRI-ESM2-0          3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "NorESM2-LM           919800\n",
      "CanESM5              551880\n",
      "BCC-ESM1             551880\n",
      "observed              46020\n",
      "Name: model, dtype: int64\n",
      "peak memory: 9445.29 MiB, increment: 2332.27 MiB\n",
      "Wall time: 32.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "### Code adapted from DSCI 525 Lecture ipynb notebook (Gittu George, 2021)\n",
    "\n",
    "dask_df = dd.read_csv(\"../data/combined_data.csv\")\n",
    "print(dask_df[\"model\"].value_counts().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-clearing",
   "metadata": {},
   "source": [
    "#### Method 3: Loading just columns what we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "decent-james",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "NorESM2-MM          3541230\n",
      "CMCC-ESM2           3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "TaiESM1             3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "SAM0-UNICON         3541153\n",
      "GFDL-ESM4           3219300\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "MRI-ESM2-0          3037320\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-LR        966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "observed              46020\n",
      "Name: model, dtype: int64\n",
      "peak memory: 4728.71 MiB, increment: 957.17 MiB\n",
      "Wall time: 36.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# The only column we want is the model column\n",
    "model_df = pd.read_csv(\"../data/combined_data.csv\", usecols=[\"model\"])\n",
    "print(model_df[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-feelings",
   "metadata": {},
   "source": [
    "### 2. Observations discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-spirituality",
   "metadata": {},
   "source": [
    "- Loading just the column we want seems to have the shortest CPU times (user 30.9 s, sys: 2.3 s, total: 33.2 s) and wall time (33.9 s). \n",
    "\n",
    "- Loading the combined data using Dask has a shorter wall time (40.6 s) than loading in chunks, however, it has longer CPU times (user 1min 24s, sys: 18.6 s, total: 1min 43s) than loading in chunks (user 59.6 s, sys: 7.12 s, total: 1min 6s).\n",
    "\n",
    "- Loading just the column we want has the minimum peak memory and increment used (1166.77 MiB and 780.00 MiB), whilst loading in chunks has the maximum peak memory and increment (1873.48 MiB, increment: 1458.30 MiB). \n",
    "\n",
    "- It is also worth noting that the memory usage from full_df.info() was memory usage: 3.3+ GB. Thus, using these methods to load the data all saved us considerable memory space. \n",
    "\n",
    "- In conclusion, loading just the column we want gives us the optimum time and space savings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-species",
   "metadata": {},
   "source": [
    "## Task 6. Perform a simple EDA in R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-allergy",
   "metadata": {},
   "source": [
    "### 1. Store data in different format\n",
    "\n",
    "Here we will write the data in 2 more different formats to compare the running time and ocuppied storage between different formats. All formats of data in this section including:\n",
    "- csv format\n",
    "- feather format\n",
    "- parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "close-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.dataset(\"../data/combined_data.csv\", format=\"csv\")\n",
    "table = dataset.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-african",
   "metadata": {},
   "source": [
    "**Feather format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "collectible-information",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "feather.write_feather(table, \"../data/example.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-turtle",
   "metadata": {},
   "source": [
    "**Parquet format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "former-saturday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pq.write_table(table, \"../data/example.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-nitrogen",
   "metadata": {},
   "source": [
    "**Check the size of data in all different formats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "arbitrary-acting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7G\t../data/combined_data.csv\n",
      "1.1G\t../data/example.feather\n",
      "542M\t../data/example.parquet\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "du -sh ../data/combined_data.csv\n",
    "du -sh ../data/example.feather\n",
    "du -sh ../data/example.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-empty",
   "metadata": {},
   "source": [
    "**Discussion:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-april",
   "metadata": {},
   "source": [
    "### 2. Transfer the dataframe from python to R and perform EDA\n",
    "\n",
    "Here we will experiment 3 exchange approaches to transfer the loaded dataset from python to R and perform EDA. In the end, we will pick one appropriate approach over others. All exchange approaches in this section including:\n",
    "- Arrow exchange\n",
    "- feather file exchange\n",
    "- parquet file exchange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-candidate",
   "metadata": {},
   "source": [
    "**Arrow exchange and EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r_table = pyra.converter.py2rpy(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "start_time <- Sys.time()\n",
    "head_df <- head(r_table)\n",
    "glimpse_df <- glimpse(r_table)\n",
    "model_count <- r_table %>% collect() %>% count(model)\n",
    "end_time <- Sys.time()\n",
    "print(class(r_table))\n",
    "print(head_df)\n",
    "print(glimpse_df)\n",
    "print(model_count)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-friend",
   "metadata": {},
   "source": [
    "**Feather file exchange and EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_feather(\"../data/example.feather\")\n",
    "head_df <- head(r_table)\n",
    "glimpse_df <- glimpse(r_table)\n",
    "model_count <- r_table %>% count(model)\n",
    "end_time <- Sys.time()\n",
    "print(class(r_table))\n",
    "print(head_df)\n",
    "print(glimpse_df)\n",
    "print(model_count)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-fundamental",
   "metadata": {},
   "source": [
    "**Parquet file exchange and EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_parquet(\"../data/example.parquet\")\n",
    "head_df <- head(r_table)\n",
    "glimpse_df <- glimpse(r_table)\n",
    "model_count <- r_table %>% count(model)\n",
    "end_time <- Sys.time()\n",
    "print(class(r_table))\n",
    "print(head_df)\n",
    "print(glimpse_df)\n",
    "print(model_count)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-routine",
   "metadata": {},
   "source": [
    "**Discussion:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-appearance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsci525]",
   "language": "python",
   "name": "conda-env-dsci525-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
